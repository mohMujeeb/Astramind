# Tool-Calling Agent

A compact, batteries-included project: build and evaluate a toolâ€‘calling agent using **LangGraph** with a controller that routes among four tools:

- **Calculator** â€” fast arithmetic via safe evaluation.
- **GSM8K Solver** â€” math word problems using an LLM prompt.
- **Web Search** â€” live fact lookup via Tavily.
- **RAG** â€” local document Q&A with FAISS + sentence-transformers.

Default model: **`llama-3.1-8b-instant`** via an OpenAIâ€‘compatible API (e.g. OpenRouter, Groq proxy, or compatible gateway).

## Quickstart

```bash
# 1) Create venv
python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\Scripts\activate)

# 2) Install deps
pip install -r requirements.txt

# 3) Configure keys
cp .env.example .env
# Fill in:
# - OPENAI_API_KEY (or a compatible provider key)
# - OPENAI_BASE_URL (e.g. https://openrouter.ai/api/v1) if not using OpenAI
# - TAVILY_API_KEY for web search
# - MODEL_NAME (defaults to llama-3.1-8b-instant)

# 4) (Optional) Ingest your local docs for RAG
python -m src.ingest --docs data/docs --index data/index

# 5) Chat from CLI
python -m src.app chat "What is the capital of France?"

# 6) Run benchmarks
bash scripts/run_benchmarks.sh
# or
python -m src.agent.eval.lama_eval
python -m src.agent.eval.gsm8k_eval
```


## Project Layout

```
ai-bootcamp-agent/
â”œâ”€ src/
â”‚  â”œâ”€ app.py                  # CLI entrypoints (chat, benchmark, ingest)
â”‚  â”œâ”€ ingest.py               # Build a local FAISS index from /data/docs
â”‚  â””â”€ agent/
â”‚     â”œâ”€ graph.py             # LangGraph: state & routing
â”‚     â”œâ”€ controller.py        # Controller logic & tool routing heuristics
â”‚     â”œâ”€ config.py            # Settings (env vars, defaults)
â”‚     â”œâ”€ llm_client.py        # OpenAI-compatible client wrapper
â”‚     â”œâ”€ tools/
â”‚     â”‚  â”œâ”€ calculator.py
â”‚     â”‚  â”œâ”€ gsm8k_solver.py
â”‚     â”‚  â”œâ”€ web_search.py
â”‚     â”‚  â””â”€ rag.py
â”‚     â”œâ”€ eval/
â”‚     â”‚  â”œâ”€ lama_eval.py
â”‚     â”‚  â””â”€ gsm8k_eval.py
â”‚     â””â”€ prompts/
â”‚        â””â”€ controller_prompt.md
â”œâ”€ data/
â”‚  â”œâ”€ docs/                   # Put your PDFs/TXTs/DOCs here for RAG ingest
â”‚  â””â”€ index/                  # Vector index output (FAISS)
â”œâ”€ scripts/
â”‚  â””â”€ run_benchmarks.sh
â”œâ”€ tests/
â”‚  â””â”€ test_tools.py
â”œâ”€ benchmarks/
â”‚  â”œâ”€ lama_subset.csv
â”‚  â””â”€ gsm8k_subset.jsonl
â”œâ”€ .env.example
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## Notes

- **LangGraph** coordinates tool calls; the controller uses light heuristics plus a modelâ€‘backed tieâ€‘breaker.
- **RAG** uses `sentence-transformers` + **FAISS** for portability.
- **Web Search** uses Tavily; swap to SerpAPI/Bing by editing `src/agent/tools/web_search.py`.
- **Benchmarks** here are **tiny** illustrative subsets; replace with your curated splits before reporting numbers.

MIT License. Enjoy! ðŸš€


### Using Groq

Set your environment like this:

```bash
cp .env.example .env
# Edit .env:
OPENAI_API_KEY=<your_groq_api_key>
OPENAI_BASE_URL=https://api.groq.com/openai/v1
MODEL_NAME=llama-3.1-8b-instant
```
